{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We run the methods of the paper on additional social networks\n",
    "### In this notebook, we run it on small offline social networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload imported files automatically without restarting the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import *\n",
    "from pathcensus import PathCensus\n",
    "from pathcensus.nullmodels import UBCM\n",
    "from pathcensus.inference import Inference\n",
    "from pathcensus.utils import set_seed\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_graph(g):\n",
    "    g = nx.Graph(g)  # remove multiedges if graph is multigraph\n",
    "    g.remove_edges_from(list(nx.selfloop_edges(g)))  # remove self-loops\n",
    "    largest_cc = max(\n",
    "        nx.connected_components(g), key=len\n",
    "    )  # get largest connected component\n",
    "    return g.subgraph(largest_cc).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_structural_measures(network_name, g, n_samples_null_model):\n",
    "    \"\"\"\n",
    "    This function calculates the structural measures of a network and \n",
    "    its null model average values by fitting a UBCM null model to the network.\n",
    "    \"\"\"\n",
    "    n_total = g.number_of_nodes()  # get total number of nodes\n",
    "    # remove self-loops and multiedges and get largest connected component\n",
    "    #g = preprocess_graph(g)  ; g\n",
    "    \n",
    "    n_giant = g.number_of_nodes()  # get number of nodes in largest connected component\n",
    "    degseq = sorted([d for n, d in g.degree()], reverse=True)  # get degree sequence\n",
    "    dataset = \"\"\n",
    "    network_name = network_name.split(\".\")[0]\n",
    "    label = \"large online\"\n",
    "    \n",
    "    properties = {\n",
    "            \"idx\": 1,\n",
    "            \"dataset\": dataset,\n",
    "            \"name\": network_name,\n",
    "            #\"graph\": [g],  # get graph\n",
    "            \"n_nodes\": n_giant,  # get number of nodes in largest connected component\n",
    "            \"frac_total\": n_giant\n",
    "            / n_total,  # get fraction of nodes in largest connected component\n",
    "            \"density\": nx.density(g),  # get density\n",
    "            \"dbar\": np.mean(degseq),  # get mean degree\n",
    "            \"dcv\": np.std(degseq)\n",
    "            / np.mean(degseq),  # get coefficient of variation of degree\n",
    "            \"dmax\": np.max(degseq),  # get maximum degree\n",
    "        }\n",
    "    \n",
    "    model = UBCM(g)  # initialize model\n",
    "    model.fit()  # fit model\n",
    "    model.validate()  # validate model\n",
    "    # compare null model to actual graph using statistics function\n",
    "    infer = Inference(g, model, statistics)\n",
    "    data, null = infer.init_comparison(n=n_samples_null_model)\n",
    "    original_network_values = dict(data)\n",
    "    original_network_values = {'data_' + k: v for k, v in original_network_values.items()}\n",
    "    null_model_mean_values = dict(null.mean(numeric_only=True)) \n",
    "    null_model_mean_values = {f'null_{n_samples_null_model}_{k}': v for k, v in null_model_mean_values.items()}\n",
    "    return properties | null_model_mean_values |original_network_values | null_model_mean_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CSV_FILE_PATH = DATA_DIR_PATH / \"structural_measures_small_offline.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7804\n",
      "Running calculations for network:  77.gml\n",
      "7896\n",
      "Running calculations for network:  78.gml\n",
      "8032\n",
      "Running calculations for network:  november17.gml\n",
      "2570133\n",
      "Running calculations for network:  sp_hospital.gml\n",
      "1996401\n",
      "Running calculations for network:  sp_kenyan_households.gml\n",
      "16319\n",
      "Running calculations for network:  terrorists_911.gml\n"
     ]
    }
   ],
   "source": [
    "file_filter = lambda file: file.is_file()\n",
    "small_offline_network_files = list(filter(file_filter, (DATA_DIR_PATH / \"offline\" / \"small\").glob(\"**/*\")))\n",
    "\n",
    "results = []\n",
    "for i, file in enumerate(small_offline_network_files): # loop over all online large social network files\n",
    "    file_size = file.stat().st_size\n",
    "    print(file_size)\n",
    "    if file_size > 200000000: \n",
    "        continue\n",
    "    f = gml_cleaner(file) # clean gml file\n",
    "    g = nx.read_gml(f, label=\"id\") # load into networkx\n",
    "    print(\"Running calculations for network: \", file.name) \n",
    "    # calculate measures from original network and null model\n",
    "    result = calculate_structural_measures(file.name.split(\".\")[0] , g, n_samples_null_model=100) \n",
    "    df = pd.DataFrame(result).reset_index()\n",
    "    df[df.columns[:-1]].to_csv(OUTPUT_CSV_FILE_PATH, mode='a', header=not OUTPUT_CSV_FILE_PATH.is_file()) # append result row to csv file\n",
    "    results.append(result) # collect results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.DataFrame(result) for result in results]).reset_index() # combine all data to dataframe for analysis\n",
    "df = df[df.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_</th>\n",
       "      <th>idx</th>\n",
       "      <th>dataset</th>\n",
       "      <th>name</th>\n",
       "      <th>n_nodes</th>\n",
       "      <th>frac_total</th>\n",
       "      <th>density</th>\n",
       "      <th>dbar</th>\n",
       "      <th>dcv</th>\n",
       "      <th>dmax</th>\n",
       "      <th>...</th>\n",
       "      <th>null_100_sim_e</th>\n",
       "      <th>null_100_comp_g</th>\n",
       "      <th>null_100_comp</th>\n",
       "      <th>null_100_comp_e</th>\n",
       "      <th>data_sim_g</th>\n",
       "      <th>data_sim</th>\n",
       "      <th>data_sim_e</th>\n",
       "      <th>data_comp_g</th>\n",
       "      <th>data_comp</th>\n",
       "      <th>data_comp_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>77</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>4.529412</td>\n",
       "      <td>0.828221</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244610</td>\n",
       "      <td>0.056841</td>\n",
       "      <td>0.048548</td>\n",
       "      <td>0.057792</td>\n",
       "      <td>0.258317</td>\n",
       "      <td>0.237123</td>\n",
       "      <td>0.276156</td>\n",
       "      <td>0.062609</td>\n",
       "      <td>0.048105</td>\n",
       "      <td>0.057827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>78</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.139037</td>\n",
       "      <td>4.588235</td>\n",
       "      <td>0.832643</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243715</td>\n",
       "      <td>0.056078</td>\n",
       "      <td>0.047906</td>\n",
       "      <td>0.056902</td>\n",
       "      <td>0.255682</td>\n",
       "      <td>0.239593</td>\n",
       "      <td>0.275417</td>\n",
       "      <td>0.060734</td>\n",
       "      <td>0.047097</td>\n",
       "      <td>0.056215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>november17</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.596708</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441896</td>\n",
       "      <td>0.063556</td>\n",
       "      <td>0.060099</td>\n",
       "      <td>0.065486</td>\n",
       "      <td>0.528662</td>\n",
       "      <td>0.429924</td>\n",
       "      <td>0.521119</td>\n",
       "      <td>0.019119</td>\n",
       "      <td>0.013873</td>\n",
       "      <td>0.018306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>sp_hospital</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.684324</td>\n",
       "      <td>864.640000</td>\n",
       "      <td>1.106573</td>\n",
       "      <td>4286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551749</td>\n",
       "      <td>0.036168</td>\n",
       "      <td>0.039116</td>\n",
       "      <td>0.038977</td>\n",
       "      <td>0.708105</td>\n",
       "      <td>0.587710</td>\n",
       "      <td>0.620922</td>\n",
       "      <td>0.018439</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.028573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>sp_kenyan_households</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.197040</td>\n",
       "      <td>1389.063830</td>\n",
       "      <td>0.884969</td>\n",
       "      <td>4193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547151</td>\n",
       "      <td>0.057008</td>\n",
       "      <td>0.061691</td>\n",
       "      <td>0.060780</td>\n",
       "      <td>0.719568</td>\n",
       "      <td>0.686484</td>\n",
       "      <td>0.696276</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.010902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>terrorists_911</td>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.080381</td>\n",
       "      <td>4.903226</td>\n",
       "      <td>0.815551</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160610</td>\n",
       "      <td>0.077721</td>\n",
       "      <td>0.057134</td>\n",
       "      <td>0.073036</td>\n",
       "      <td>0.360882</td>\n",
       "      <td>0.292575</td>\n",
       "      <td>0.365698</td>\n",
       "      <td>0.014225</td>\n",
       "      <td>0.010214</td>\n",
       "      <td>0.013378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _  idx dataset                  name  n_nodes  frac_total    density  \\\n",
       "0  0    1                            77       34         1.0   0.137255   \n",
       "1  0    1                            78       34         1.0   0.139037   \n",
       "2  0    1                    november17       22         1.0   0.285714   \n",
       "3  0    1                   sp_hospital       75         1.0  11.684324   \n",
       "4  0    1          sp_kenyan_households       47         1.0  30.197040   \n",
       "5  0    1                terrorists_911       62         1.0   0.080381   \n",
       "\n",
       "          dbar       dcv  dmax  ...  null_100_sim_e  null_100_comp_g  \\\n",
       "0     4.529412  0.828221    16  ...        0.244610         0.056841   \n",
       "1     4.588235  0.832643    17  ...        0.243715         0.056078   \n",
       "2     6.000000  0.596708    14  ...        0.441896         0.063556   \n",
       "3   864.640000  1.106573  4286  ...        0.551749         0.036168   \n",
       "4  1389.063830  0.884969  4193  ...        0.547151         0.057008   \n",
       "5     4.903226  0.815551    22  ...        0.160610         0.077721   \n",
       "\n",
       "   null_100_comp  null_100_comp_e  data_sim_g  data_sim  data_sim_e  \\\n",
       "0       0.048548         0.057792    0.258317  0.237123    0.276156   \n",
       "1       0.047906         0.056902    0.255682  0.239593    0.275417   \n",
       "2       0.060099         0.065486    0.528662  0.429924    0.521119   \n",
       "3       0.039116         0.038977    0.708105  0.587710    0.620922   \n",
       "4       0.061691         0.060780    0.719568  0.686484    0.696276   \n",
       "5       0.057134         0.073036    0.360882  0.292575    0.365698   \n",
       "\n",
       "   data_comp_g  data_comp  data_comp_e  \n",
       "0     0.062609   0.048105     0.057827  \n",
       "1     0.060734   0.047097     0.056215  \n",
       "2     0.019119   0.013873     0.018306  \n",
       "3     0.018439   0.027397     0.028573  \n",
       "4     0.009628   0.010332     0.010902  \n",
       "5     0.014225   0.010214     0.013378  \n",
       "\n",
       "[6 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional, Dict, Iterable\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib import patheffects\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from src.utils import get_root_path\n",
    "\n",
    "\n",
    "sns.set_theme(\n",
    "    style=\"ticks\",\n",
    "    font_scale=1.5,\n",
    "    rc={ \n",
    "        \"figure.figsize\": (15, 8), \n",
    "        \"font.size\": 14,\n",
    "    }\n",
    ")\n",
    "\n",
    "COLORS = (\n",
    "    \"#EB7159\", \n",
    "    \"#66C8E6\", \n",
    "    \"#AB65B5\", \n",
    "    \"#829F49\",\n",
    "    \"#6876CE\",\n",
    "    \"#BE8A3B\",\n",
    "    \"#CF5786\",\n",
    "    \"#AD483A\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrum(\n",
    "    data: pd.DataFrame,\n",
    "    ax: mpl.axes.Axes,\n",
    "    *,\n",
    "    colors: Iterable[str] = COLORS[:2],\n",
    "    coefs: Iterable[str] = (\"sim\", \"comp\"),\n",
    "    ci: float = .95,\n",
    "    plot_kws: Optional[Dict] = None,\n",
    "    scatter_kws: Optional[Dict] = None,\n",
    "    ci_kws: Optional[Dict] = None,\n",
    "    logx: bool = True,\n",
    "    logy: bool = False\n",
    ") -> None:\n",
    "    \"\"\"Plot structural coefficients spectrum for a given network.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "        Data frame with observed and null model data\n",
    "        grouped in node degree bins.\n",
    "    ax\n",
    "        Axes to use for plotting.\n",
    "    \"\"\"\n",
    "    assert len(coefs) == len(colors),\\\n",
    "    \"'coefs' and 'colors' must have the same length\"\n",
    "\n",
    "    alpha = 1 - ci\n",
    "    cols  = [ \"dbin\", *coefs ]\n",
    "\n",
    "    odf = data.loc[data[\"which\"] == \"observed\", cols]\n",
    "    ndf = data.loc[data[\"which\"] == \"randomized\", cols] \n",
    "    \n",
    "    mean = ndf.groupby(\"dbin\").mean().reset_index()\n",
    "    low  = ndf.groupby(\"dbin\").quantile(alpha/2).reset_index()\n",
    "    high = ndf.groupby(\"dbin\").quantile(1 - alpha/2).reset_index()\n",
    "\n",
    "    plot_kws    = { **LINE_PARAMS, **(plot_kws or {}) }\n",
    "    scatter_kws = { \"edgecolors\": \"white\", \"zorder\": 100, **(scatter_kws or {}) }\n",
    "    ci_kws      = ci_kws or {}\n",
    "\n",
    "    # Plot observed trend\n",
    "    for coef, color in zip(coefs, colors):\n",
    "        # plot line\n",
    "        args = (odf[\"dbin\"], odf[coef])\n",
    "        kws  = { \"color\": color, \"ls\": \"-\", **plot_kws }\n",
    "        ax.plot(*args, **kws)\n",
    "        # plot markers\n",
    "        kws = { \"color\": color, \"marker\": \"o\", \"s\": 150, **scatter_kws }\n",
    "        ax.scatter(*args, **kws)\n",
    "    \n",
    "    # Plot null model trend\n",
    "    for coef, color in zip(coefs, colors):\n",
    "        # plot line\n",
    "        args = (mean[\"dbin\"], mean[coef])\n",
    "        kws  = { \"color\": color, \"ls\": \"--\", **plot_kws }\n",
    "        ax.plot(*args, **kws)\n",
    "        # plot CI\n",
    "        args = (mean[\"dbin\"], low[coef], high[coef])\n",
    "        kws = { \"color\": color, \"alpha\": .2, **ci_kws }\n",
    "        ax.fill_between(*args, **kws)\n",
    "\n",
    "        label = data[\"label\"].iloc[0]\n",
    "        ax.set_title(label, **FONTS)\n",
    "\n",
    "    # Customize aethetics\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=12)\n",
    "    ax.tick_params(axis=\"both\", which=\"minor\", labelsize=12)\n",
    "    formatter = mpl.ticker.FormatStrFormatter(\"%.2f\")\n",
    "    ax.yaxis.set_major_formatter(formatter)\n",
    "    # Transform axes\n",
    "    if logx:\n",
    "        ax.set_xscale(\"log\", base=2)\n",
    "    if logy:\n",
    "        ax.set_yscale(\"log\", base=2)\n",
    "\n",
    "\n",
    "def get_legend_spec(\n",
    "    lw: int = 6,\n",
    "    *,\n",
    "    colors: Iterable[str] = COLORS[:2],\n",
    "    labels: Iterable[str] = (r\"$s_i$\", r\"$c_i$\")\n",
    ") -> Iterable:\n",
    "    \"\"\"Get legend specification for the plot.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lw\n",
    "        Line width.\n",
    "    \"\"\"\n",
    "    assert len(colors) == len(labels),\\\n",
    "        \"'colors' and 'labels' must have the same length\"\n",
    "    lines = [\n",
    "        mpl.lines.Line2D([0], [0], color=color, lw=lw)\n",
    "        for color in colors \n",
    "    ]\n",
    "    return lines, list(labels)\n",
    "\n",
    "def get_legend_box_params(**kwds: Any) -> Dict:\n",
    "    \"\"\"Get legend box param dictionary.\"\"\"\n",
    "    return {\n",
    "        \"fontsize\": 18,\n",
    "        \"edgecolor\": \"black\",\n",
    "        \"facecolor\": \"#F4F4F4\",\n",
    "        **kwds\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.237123\n",
       "1    0.239593\n",
       "2    0.429924\n",
       "3    0.587710\n",
       "4    0.686484\n",
       "       ...   \n",
       "1    0.056215\n",
       "2    0.018306\n",
       "3    0.028573\n",
       "4    0.010902\n",
       "5    0.013378\n",
       "Length: 72, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.concat([df['data_sim'],df['data_sim_e'],df['null_100_sim_e'],df['null_100_comp_g'],df['null_100_comp'],df['null_100_comp_e'],df['data_sim_g'],df['data_sim'],df['data_sim_e'],df['data_comp_g'],df['data_comp']\t,df['data_comp_e']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7834f9b8d13c44e0f0826d8b407fec1bf1900567cafe26a1cf17c6c277bc2c6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
