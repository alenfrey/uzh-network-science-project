{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload imported files automatically without restarting the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import *\n",
    "from pathcensus import PathCensus\n",
    "from pathcensus.nullmodels import UBCM\n",
    "from pathcensus.inference import Inference\n",
    "from pathcensus.utils import set_seed\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_filter = lambda file: file.is_file()\n",
    "friendship_networks_file_names = list(\n",
    "    filter(file_filter, (DATA_DIR_PATH / \"offline\").glob(\"**/friendship*\"))\n",
    ")\n",
    "health_advice_networks_file_names = list(\n",
    "    filter(file_filter, (DATA_DIR_PATH / \"offline\").glob(\"**/health-advice*\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/af/Projects/uzh-network-science-project/data/offline/medium/ugandan_village/health-advice_1.gml'),\n",
       " PosixPath('/Users/af/Projects/uzh-network-science-project/data/offline/medium/ugandan_village/health-advice_2.gml'),\n",
       " PosixPath('/Users/af/Projects/uzh-network-science-project/data/offline/medium/ugandan_village/health-advice_3.gml')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the networks\n",
    "friendship_networks_file_names = sorted(\n",
    "    friendship_networks_file_names,\n",
    "    key=lambda path: get_digits_from_string(path.name).zfill(2),\n",
    ")\n",
    "\n",
    "health_advice_networks_file_names = sorted(\n",
    "    health_advice_networks_file_names,\n",
    "    key=lambda path: get_digits_from_string(path.name).zfill(2),\n",
    ")\n",
    "\n",
    "health_advice_networks_file_names[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ugandan_village_networks = (\n",
    "    friendship_networks_file_names + health_advice_networks_file_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_graph(g):\n",
    "    g = nx.Graph(g)  # remove multiedges if graph is multigraph\n",
    "    g.remove_edges_from(list(nx.selfloop_edges(g)))  # remove self-loops\n",
    "    largest_cc = max(\n",
    "        nx.connected_components(g), key=len\n",
    "    )  # get largest connected component\n",
    "    return g.subgraph(largest_cc).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1019)\n",
    "N_SAMPLES = 200\n",
    "results = []\n",
    "\n",
    "for network_path in ugandan_village_networks:\n",
    "    g = nx.read_gml(gml_cleaner(network_path), label=\"id\")  # read graph\n",
    "    n_total = g.number_of_nodes()  # get total number of nodes\n",
    "    g = preprocess_graph(\n",
    "        g\n",
    "    )  # remove self-loops and multiedges and get largest connected component\n",
    "    n_giant = g.number_of_nodes()  # get number of nodes in largest connected component\n",
    "    degseq = sorted([d for n, d in g.degree()], reverse=True)  # get degree sequence\n",
    "\n",
    "    dataset = \"ugandan_village\"\n",
    "    network_name = network_path.stem\n",
    "    domain = \"social\"\n",
    "    relation = \"friendship\" if \"friendship\" in network_name else \"health advice\"\n",
    "    desc = \"offline\"\n",
    "\n",
    "    label = (\n",
    "        \"Friendship ({})\".format(get_digits_from_string(str(network_path)))\n",
    "        if \"friendship\" in network_name\n",
    "        else \"Advice ({})\".format(get_digits_from_string(str(network_path)))\n",
    "    )\n",
    "\n",
    "    net = pd.DataFrame(\n",
    "        {\n",
    "            \"idx\": int(get_digits_from_string(str(network_path))),\n",
    "            \"dataset\": dataset,\n",
    "            \"name\": network_name,\n",
    "            \"domain\": domain,\n",
    "            \"relation\": relation,\n",
    "            \"desc\": desc,\n",
    "            \"label\": label,\n",
    "            \"graph\": [g],  # get graph\n",
    "            \"n_nodes\": n_giant,  # get number of nodes in largest connected component\n",
    "            \"frac_total\": n_giant\n",
    "            / n_total,  # get fraction of nodes in largest connected component\n",
    "            \"density\": nx.density(g),  # get density\n",
    "            \"dbar\": np.mean(degseq),  # get mean degree\n",
    "            \"dcv\": np.std(degseq)\n",
    "            / np.mean(degseq),  # get coefficient of variation of degree\n",
    "            \"dmax\": np.max(degseq),  # get maximum degree\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    # fit UBCM null model\n",
    "    model = UBCM(g)  # initialize model\n",
    "    model.fit()  # fit model\n",
    "    model.validate()  # validate model\n",
    "    # compare null model to actual graph using statistics function\n",
    "    infer = Inference(g, model, statistics)\n",
    "    data, null = infer.init_comparison(n=N_SAMPLES)\n",
    "\n",
    "    # Estimate fractions of significant nodes\n",
    "    odf = pd.concat(data.pop(\"coefs\").tolist())\n",
    "    ndf = pd.concat(null.pop(\"coefs\").tolist())\n",
    "\n",
    "    infer.add_stats_index(odf)\n",
    "    infer.add_stats_index(ndf)\n",
    "\n",
    "    odf = pd.concat([odf], keys=[0], names=[\"_\"])\n",
    "    ndf = pd.concat([ndf], keys=[0], names=[\"_\"])\n",
    "\n",
    "    alpha = 0.01\n",
    "    pvals = infer.estimate_pvalues(odf, ndf, alpha=alpha, adjust=True)\n",
    "    sig = (pvals <= alpha)[[\"sim\", \"comp\"]]\n",
    "\n",
    "    sig[\"both\"] = sig.all(axis=1)\n",
    "    sig = sig.mean().to_frame().T\n",
    "\n",
    "    # Compute calibrated coefficients\n",
    "    cdata = (\n",
    "        np.log(data / null)\n",
    "        .reset_index(drop=True)\n",
    "        .replace([np.inf, -np.inf], np.nan)\n",
    "        .dropna()\n",
    "        .mean()\n",
    "        .to_frame()\n",
    "        .T\n",
    "    )\n",
    "\n",
    "    net[\"rawdata\"] = [data]\n",
    "    net[\"calibrated\"] = [cdata]\n",
    "    net[\"significant\"] = [sig]\n",
    "\n",
    "    results.append(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/af/Projects/uzh-network-science-project/data/social.pkl.gz']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villages = pd.concat(results, axis=0, ignore_index=True)  # concatenate dataframes\n",
    "joblib.dump(villages, DATA_DIR_PATH / \"social.pkl.gz\", compress=True)  # save data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('nsp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "322ce98f348e1b728bd0f7459d7c0a9c228a96f87ab30036517d385db03c9650"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
