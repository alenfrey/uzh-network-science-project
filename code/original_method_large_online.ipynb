{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We run the methods of the paper on additional social networks\n",
    "### In this notebook, we run it on large online social networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload imported files automatically without restarting the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import *\n",
    "from pathcensus import PathCensus\n",
    "from pathcensus.nullmodels import UBCM\n",
    "from pathcensus.inference import Inference\n",
    "from pathcensus.utils import set_seed\n",
    "from mandarina.benchmark import timer\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def calculate_structural_measures(network_name, g, n_samples_null_model):\n",
    "    \"\"\"\n",
    "    This function calculates the structural measures of a network and \n",
    "    its null model average values by fitting a UBCM null model to the network.\n",
    "    \"\"\"\n",
    "    n_total = g.number_of_nodes()  # get total number of nodes\n",
    "    # remove self-loops and multiedges and get largest connected component\n",
    "    g = preprocess_graph(g)  ; g\n",
    "    n_giant = g.number_of_nodes()  # get number of nodes in largest connected component\n",
    "    degseq = sorted([d for n, d in g.degree()], reverse=True)  # get degree sequence\n",
    "    dataset = \"\"\n",
    "    network_name = network_name.split(\".\")[0]\n",
    "    label = \"large online\"\n",
    "    \n",
    "    properties = {\n",
    "            \"idx\": 1,\n",
    "            \"dataset\": dataset,\n",
    "            \"name\": network_name,\n",
    "            #\"graph\": [g],  # get graph\n",
    "            \"n_nodes\": n_giant,  # get number of nodes in largest connected component\n",
    "            \"frac_total\": n_giant\n",
    "            / n_total,  # get fraction of nodes in largest connected component\n",
    "            \"density\": nx.density(g),  # get density\n",
    "            \"dbar\": np.mean(degseq),  # get mean degree\n",
    "            \"dcv\": np.std(degseq)\n",
    "            / np.mean(degseq),  # get coefficient of variation of degree\n",
    "            \"dmax\": np.max(degseq),  # get maximum degree\n",
    "        }\n",
    "    \n",
    "    model = UBCM(g)  # initialize model\n",
    "    model.fit()  # fit model\n",
    "    model.validate()  # validate model\n",
    "    # compare null model to actual graph using statistics function\n",
    "    infer = Inference(g, model, statistics)\n",
    "    data, null = infer.init_comparison(n=n_samples_null_model)\n",
    "    original_network_values = dict(data)\n",
    "    original_network_values = {'data_' + k: v for k, v in original_network_values.items()}\n",
    "    null_model_mean_values = dict(null.mean(numeric_only=True)) \n",
    "    null_model_mean_values = {f'null_{n_samples_null_model}_{k}': v for k, v in null_model_mean_values.items()}\n",
    "    return properties | null_model_mean_values |original_network_values | null_model_mean_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CSV_FILE_PATH = DATA_DIR_PATH / \"structural_measures_large_online.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2533001\n",
      "Running calculations for network:  NYC_restaurant_tips.gml\n",
      "Function calculate_structural_measures with args (('NYC_restaurant_tips', <networkx.classes.multigraph.MultiGraph object at 0x7f9235c1e2f0>), {'n_samples_null_model': 200}) took: 57.2723 seconds.\n",
      "2427918\n",
      "Running calculations for network:  NYC_restaurant_checkin.gml\n",
      "Function calculate_structural_measures with args (('NYC_restaurant_checkin', <networkx.classes.multigraph.MultiGraph object at 0x7f9237ccef80>), {'n_samples_null_model': 200}) took: 52.4804 seconds.\n",
      "2019618248\n",
      "Running calculations for network:  band.gml\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "file_filter = lambda file: file.is_file()\n",
    "large_online_network_files = list(filter(file_filter, (DATA_DIR_PATH / \"online\" / \"large\").glob(\"**/*\")))\n",
    "\n",
    "results = []\n",
    "for i, file in enumerate(large_online_network_files): # loop over all online large social network files\n",
    "    file_size = file.stat().st_size\n",
    "    print(file_size)\n",
    "    #if file_size > 3000000: \n",
    "    #    continue\n",
    "    f = gml_cleaner(file) # clean gml file\n",
    "    g = nx.read_gml(f, label=\"id\") # load into networkx\n",
    "    print(\"Running calculations for network: \", file.name) \n",
    "    # calculate measures from original network and null model\n",
    "    result = calculate_structural_measures(file.name.split(\".\")[0] , g, n_samples_null_model=200) \n",
    "    df = pd.DataFrame(result).reset_index()\n",
    "    df[df.columns[:-1]].to_csv(OUTPUT_CSV_FILE_PATH, mode='a', header=not OUTPUT_CSV_FILE_PATH.is_file()) # append result row to csv file\n",
    "    results.append(result) # collect results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.DataFrame(result) for result in results]).reset_index() # combine all data to dataframe for analysis\n",
    "df = df[df.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_</th>\n",
       "      <th>idx</th>\n",
       "      <th>dataset</th>\n",
       "      <th>name</th>\n",
       "      <th>n_nodes</th>\n",
       "      <th>frac_total</th>\n",
       "      <th>density</th>\n",
       "      <th>dbar</th>\n",
       "      <th>dcv</th>\n",
       "      <th>dmax</th>\n",
       "      <th>...</th>\n",
       "      <th>null_200_sim_e</th>\n",
       "      <th>null_200_comp_g</th>\n",
       "      <th>null_200_comp</th>\n",
       "      <th>null_200_comp_e</th>\n",
       "      <th>data_sim_g</th>\n",
       "      <th>data_sim</th>\n",
       "      <th>data_sim_e</th>\n",
       "      <th>data_comp_g</th>\n",
       "      <th>data_comp</th>\n",
       "      <th>data_comp_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>NYC_restaurant_tips</td>\n",
       "      <td>5372</td>\n",
       "      <td>0.838066</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>3.295607</td>\n",
       "      <td>1.569503</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014416</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.006515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>NYC_restaurant_checkin</td>\n",
       "      <td>4906</td>\n",
       "      <td>0.993922</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>5.485936</td>\n",
       "      <td>1.044863</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003466</td>\n",
       "      <td>0.004668</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011630</td>\n",
       "      <td>0.005808</td>\n",
       "      <td>0.008769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _  idx dataset                    name  n_nodes  frac_total   density  \\\n",
       "0  0    1             NYC_restaurant_tips     5372    0.838066  0.000614   \n",
       "1  0    1          NYC_restaurant_checkin     4906    0.993922  0.001118   \n",
       "\n",
       "       dbar       dcv  dmax  ...  null_200_sim_e  null_200_comp_g  \\\n",
       "0  3.295607  1.569503   196  ...        0.003327         0.004644   \n",
       "1  5.485936  1.044863    88  ...        0.003466         0.004668   \n",
       "\n",
       "   null_200_comp  null_200_comp_e  data_sim_g  data_sim  data_sim_e  \\\n",
       "0       0.001351         0.002529         0.0       0.0         0.0   \n",
       "1       0.002053         0.003247         0.0       0.0         0.0   \n",
       "\n",
       "   data_comp_g  data_comp  data_comp_e  \n",
       "0     0.014416   0.003092     0.006515  \n",
       "1     0.011630   0.005808     0.008769  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45e9e9119b36140a2a9bca0259b0a24ad8917ae126aa158bf5a8fa6cf8c03ef3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
