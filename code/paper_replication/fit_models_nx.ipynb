{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# reload imported files automatically without restarting the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import *\n",
    "from pathcensus import PathCensus\n",
    "from pathcensus.nullmodels import UBCM\n",
    "from pathcensus.inference import Inference\n",
    "from pathcensus.utils import set_seed\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(graph: ig.Graph) -> pd.DataFrame:\n",
    "    \"\"\"Function for calculating graph statistics.\"\"\"\n",
    "    paths = PathCensus(graph)\n",
    "    coefs = paths.coefs(\"nodes\")\n",
    "    df = pd.DataFrame({\n",
    "        \"sim_g\":   paths.similarity(\"global\"),\n",
    "        \"sim\":     coefs[\"sim\"].mean(),\n",
    "        \"sim_e\":   paths.similarity(\"edges\").mean(),\n",
    "        \"comp_g\":  paths.complementarity(\"global\"),\n",
    "        \"comp\":    coefs[\"comp\"].mean(),\n",
    "        \"comp_e\":  paths.complementarity(\"edges\").mean(),\n",
    "        \"coefs\":   [coefs]\n",
    "    }, index=[0])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_filter = lambda file: file.is_file()\n",
    "friendship_networks_file_names = list(filter(file_filter, (DATA_DIR_PATH / \"offline\").glob(\"**/friendship*\")))\n",
    "health_advice_networks_file_names = list(filter(file_filter, (DATA_DIR_PATH / \"offline\").glob(\"**/health-advice*\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/af/Projects/uzh-network-science-project/data/offline/medium/ugandan_village/health-advice_1.gml'),\n",
       " PosixPath('/home/af/Projects/uzh-network-science-project/data/offline/medium/ugandan_village/health-advice_2.gml'),\n",
       " PosixPath('/home/af/Projects/uzh-network-science-project/data/offline/medium/ugandan_village/health-advice_3.gml')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the networks\n",
    "friendship_networks_file_names = sorted(\n",
    "    friendship_networks_file_names,\n",
    "    key=lambda path: get_digits_from_string(path.name).zfill(2),\n",
    ")\n",
    "\n",
    "health_advice_networks_file_names = sorted(\n",
    "    health_advice_networks_file_names,\n",
    "    key=lambda path: get_digits_from_string(path.name).zfill(2),\n",
    ")\n",
    "\n",
    "health_advice_networks_file_names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "ugandan_village_networks = friendship_networks_file_names + health_advice_networks_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1019)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_graph(g):\n",
    "    g = nx.Graph(g) # remove multiedges if graph is multigraph\n",
    "    g.remove_edges_from(list(nx.selfloop_edges(g))) # remove self-loops\n",
    "    largest_cc = max(nx.connected_components(g), key=len) # get largest connected component\n",
    "    return g.subgraph(largest_cc).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network_path in ugandan_village_networks:\n",
    "    g = nx.read_gml(gml_cleaner(network_path), label=\"id\") # read graph\n",
    "    n_total = g.number_of_nodes() # get total number of nodes\n",
    "    g = preprocess_graph(g) # remove self-loops and multiedges and get largest connected component\n",
    "    n_giant = g.number_of_nodes() # get number of nodes in largest connected component\n",
    "    degseq = sorted([d for n, d in g.degree()], reverse=True) # get degree sequence\n",
    "\n",
    "    dataset = \"ugandan_village\"\n",
    "    network_name = network_path.stem\n",
    "    domain = \"social\"\n",
    "    relation = \"friendship\" if \"friendship\" in network_name else \"health advice\"\n",
    "    desc = \"offline\"\n",
    "\n",
    "    label = (\n",
    "        \"Friendship ({})\".format(get_digits_from_string(str(network_path)))\n",
    "        if \"friendship\" in network_name\n",
    "        else \"Advice ({})\".format(get_digits_from_string(str(network_path)))\n",
    "    )\n",
    "\n",
    "    net = pd.DataFrame({\n",
    "        \"idx\": int(get_digits_from_string(str(network_path))),\n",
    "        \"dataset\": dataset,\n",
    "        \"name\": network_name,\n",
    "        \"domain\": domain,\n",
    "        \"relation\": relation,\n",
    "        \"desc\": desc,\n",
    "        \"label\": label, \n",
    "        \"graph\": [g], # get graph\n",
    "        \"n_nodes\": n_giant, # get number of nodes in largest connected component\n",
    "        \"frac_total\": n_giant / n_total, # get fraction of nodes in largest connected component\n",
    "        \"density\":    nx.density(g), # get density\n",
    "        \"dbar\":       np.mean(degseq), # get mean degree\n",
    "        \"dcv\":        np.std(degseq) / np.mean(degseq), # get coefficient of variation of degree\n",
    "        \"dmax\":       np.max(degseq) # get maximum degree\n",
    "    }, index=[0])\n",
    "\n",
    "\n",
    "     # fit UBCM null model\n",
    "    model = UBCM(g) # initialize model\n",
    "    model.fit() # fit model     \n",
    "    model.validate() # validate model\n",
    "    # compare null model to actual graph using statistics function\n",
    "    infer = Inference(g, model, statistics) \n",
    "    data, null = infer.init_comparison(n=N_SAMPLES) \n",
    "\n",
    "    # Estimate fractions of significant nodes\n",
    "    odf = pd.concat(data.pop(\"coefs\").tolist())\n",
    "    ndf = pd.concat(null.pop(\"coefs\").tolist())\n",
    "\n",
    "    infer.add_stats_index(odf)\n",
    "    infer.add_stats_index(ndf)\n",
    "\n",
    "    odf = pd.concat([odf], keys=[0], names=[\"_\"])\n",
    "    ndf = pd.concat([ndf], keys=[0], names=[\"_\"])\n",
    "\n",
    "    alpha = 0.01\n",
    "    pvals = infer.estimate_pvalues(odf, ndf, alpha=alpha, adjust=True)\n",
    "    sig   = (pvals <= alpha)[[\"sim\", \"comp\"]]\n",
    "\n",
    "    sig[\"both\"] = sig.all(axis=1)\n",
    "    sig = sig.mean().to_frame().T\n",
    "\n",
    "    # Compute calibrated coefficients\n",
    "    cdata = np.log(data / null).reset_index(drop=True) \\\n",
    "        .replace([np.inf, -np.inf], np.nan) \\\n",
    "        .dropna() \\\n",
    "        .mean() \\\n",
    "        .to_frame().T\n",
    "\n",
    "    net[\"rawdata\"]     = [data]\n",
    "    net[\"calibrated\"]  = [cdata]\n",
    "    net[\"significant\"] = [sig]\n",
    "    rawdata.append(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/af/Projects/uzh-network-science-project/data/social.pkl.gz']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villages = pd.concat(rawdata, axis=0, ignore_index=True) # concatenate dataframes\n",
    "joblib.dump(villages, DATA_DIR_PATH / \"social.pkl.gz\", compress=True) # save data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45e9e9119b36140a2a9bca0259b0a24ad8917ae126aa158bf5a8fa6cf8c03ef3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
